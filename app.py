'''
Author: Daniel
'''
import gradio as gr
import os
import random
from funaudiowarp import SenseVoiceNode
from funaudiowarp import CosyVoiceSFTNode, CosyVoiceNaturalNode, CosyVoiceDualLanglNode, CosyVoiceSpeakerVoiceNode, CosyVoiceSpeakerCreaterNode
from funaudio_utils.download_models import ModelDownloader

base_path = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(base_path, "models")
speaker_path = os.path.join(model_path, 'Speaker')
model_downloader = ModelDownloader(model_path)

sft_spk_list = ['ä¸­æ–‡å¥³', 'ä¸­æ–‡ç”·', 'æ—¥è¯­ç”·', 'ç²¤è¯­å¥³', 'è‹±æ–‡å¥³', 'è‹±æ–‡ç”·', 'éŸ©è¯­å¥³']

instruct_list = [
    ["Selene 'Moonshade', is a mysterious, elegant dancer with a connection to the night. Her movements are both mesmerizing and deadly."],
    ["A female speaker with normal pitch, slow speaking rate, and sad emotion."],
    ["Priya, the humanitarian doctor, heals wounds of the world with her boundless empathy and skill."],
    ["Zara \"Wildfire, is an impulsive, fearless firebrand who loves a challenge. Her bravery inspires others, though she often acts recklessly."],
    ["Kai'Torrent, is a cool-headed, tactical water mage who plans his moves carefully. A soothing presence with hidden depths."],
    ["Kai'Torrent, is a cool-headed, tactical water mage who plans his moves carefully. A soothing presence with hidden depths."],
    ["Ivan, the old sea captain, navigates life's storms with timeless wisdom and a heart of gold."]
]

natural_txt_list = [
    ['åœ¨é¢å¯¹æŒ‘æˆ˜æ—¶ï¼Œä»–å±•ç°äº†éå‡¡çš„<strong>å‹‡æ°”</strong>ä¸<strong>æ™ºæ…§</strong>ã€‚']
]

def get_text_by_sensevoice(audio_input, use_fast_model, punc_segment):
    '''
    è°ƒç”¨SenseVoiceçš„è¯­éŸ³è¯†åˆ«æ¥å£
    '''
    sensevoice_node = SenseVoiceNode(base_path, model_downloader)
    return sensevoice_node.generate(audio_input, use_fast_model, punc_segment),
def create_voice_by_pretrained(tts_text, predefined_model, speed_input, seed, use_25hz_flag):
    '''
    è°ƒç”¨CosyVoiceçš„é¢„å®šä¹‰æ¨¡å‹ç”Ÿæˆè¯­éŸ³
    '''
    cosyvoice_sft_node = CosyVoiceSFTNode(base_path, model_downloader)
    output = cosyvoice_sft_node.generate(tts_text, predefined_model, float(speed_input), int(seed), use_25hz_flag)
    return output

def create_voice_by_natural_lang(tts_text_for_natural_lang, instruct_text, predefined_model, speed_input, seed):
    '''
    è°ƒç”¨CosyVoiceçš„é¢„å®šä¹‰æ¨¡å‹å’ŒæŒ‡ä»¤æ–‡æœ¬ç”Ÿæˆè¯­éŸ³
    '''
    cosyvoice_natural_node = CosyVoiceNaturalNode(base_path, model_downloader)
    output = cosyvoice_natural_node.generate(tts_text_for_natural_lang, instruct_text, predefined_model, float(speed_input), int(seed))
    return output

def create_voice_by_dual_lang(sample_audio, tts_text_for_dual_lang, speed_input, seed, use_25hz_flag):
    '''
    ä½¿ç”¨è·¨è¯­è¨€æ¨¡å‹ç”Ÿæˆè¯­éŸ³
    '''
    cosyvoice_dual_lang_node = CosyVoiceDualLanglNode(base_path, model_downloader)
    output = cosyvoice_dual_lang_node.generate(sample_audio, tts_text_for_dual_lang, float(speed_input), int(seed), use_25hz_flag)
    return output

def create_voice_by_cloned_model(speaker_model_name, speaker_model_dir, tts_text, speed_input, seed, use_25hz_flag):
    '''
    ä½¿ç”¨å…‹éš†è¯­éŸ³æ¨¡å‹æŒ‰é’®
    '''
    cosyvoice_speaker_voice_node = CosyVoiceSpeakerVoiceNode(base_path, model_downloader)
    output = cosyvoice_speaker_voice_node.generate(speaker_model_name, speaker_model_dir, tts_text, float(speed_input), int(seed), use_25hz_flag)
    return output

def create_voice_model(sample_audio, speaker_model_name, speaker_model_dir, tts_text, prompt_text, speed_input, seed, use_25hz_flag):
    '''
    ç”Ÿæˆè¯­éŸ³å…‹éš†æ¨¡å‹
    '''
    cosyvoice_speaker_create_node = CosyVoiceSpeakerCreaterNode(base_path, model_downloader)
    output = cosyvoice_speaker_create_node.generate(sample_audio, tts_text, prompt_text, speaker_model_name, speaker_model_dir, float(speed_input), int(seed), use_25hz_flag)
    return output

def generate_seed():
    '''
    ç”Ÿæˆéšæœºç§å­
    '''
    seed = random.randint(1, 100000000)
    return seed

def common_param_layout():
    '''
    é€šç”¨çš„å‚æ•°å¸ƒå±€
    '''
    with gr.Row():
        speed_input = gr.Slider(label="è¯­é€Ÿ", minimum=0.5, maximum=2, step=0.1, value=1.0)
    
    with gr.Row(elem_id="seed-row"):  # Add an ID to the row for styling
        seed_btn = gr.Button("ğŸ²", scale=0)
        seed = gr.Number(value=generate_seed(), show_label=False, scale=1)
        
    with gr.Row():
        use_25hz_flag = gr.Checkbox(label='ä½¿ç”¨25Hzé‡‡æ ·ç‡', value=False)

    seed_btn.click(
        fn=generate_seed,
        inputs=[],
        outputs=[seed]
    )

    return speed_input, seed, use_25hz_flag
 
def sensevoice_layout():
    '''
    SenseVoiceèŠ‚ç‚¹å¸ƒå±€
    '''
    audio_input = gr.Audio(label='æºéŸ³é¢‘æ–‡ä»¶')
    use_fast_model = gr.Checkbox(label='ä½¿ç”¨å¿«é€Ÿæ¨¡å‹', value=False)
    punc_segment = gr.Checkbox(label='æ·»åŠ æ ‡ç‚¹ç¬¦å·', value=True)
    
    return audio_input, use_fast_model, punc_segment
                                 
def cosyvoice_pretrained_model_node():
    '''
    CosyVoiceé¢„å®šä¹‰æ¨¡å‹çš„èŠ‚ç‚¹å¸ƒå±€
    '''
    tts_text = gr.TextArea(label='TTSæ–‡æœ¬ï¼ˆåˆæˆæ–‡æœ¬ï¼‰',lines=5)
    predefined_model = gr.Dropdown(choices=sft_spk_list, label='é¢„è®­ç»ƒæ¨¡å‹', value='ä¸­æ–‡å¥³')
    speed_input, seed, use_25hz_flag = common_param_layout()
   
    return tts_text, predefined_model, speed_input, seed, use_25hz_flag

def cosyvoice_natural_lang_control_node():
    '''
    CosyVoiceè‡ªç„¶è¯­è¨€æ§åˆ¶èŠ‚ç‚¹å¸ƒå±€
    '''
    with gr.Row():
        tts_text = gr.TextArea(label='TTSæ–‡æœ¬ï¼ˆåˆæˆæ–‡æœ¬ï¼‰',lines=5)
    with gr.Row():
        gr.Examples(
            examples = natural_txt_list,
            inputs=[tts_text]
        )
    with gr.Row():
        instruct_text = gr.TextArea(label='Instructæ–‡æœ¬ï¼ˆæè¿°è¯­éŸ³çŠ¶æ€ï¼‰',lines=3)
    with gr.Row():
        gr.Examples(
            examples = instruct_list,
            inputs=[instruct_text]
        )
    
    with gr.Row():
        predefined_model = gr.Dropdown(choices=sft_spk_list, label='é¢„è®­ç»ƒæ¨¡å‹', value='ä¸­æ–‡å¥³')
    
    speed_input, seed, _ = common_param_layout()
    
    return tts_text, instruct_text, predefined_model, speed_input, seed

def cosyvoice_dual_lang_clone_node():
    '''
    CosyVoiceè·¨è¯­è¨€å…‹éš†èŠ‚ç‚¹å¸ƒå±€
    '''
    sample_audio = gr.Audio(label='éŸ³é¢‘æ–‡ä»¶ï¼ˆæ ·ä¾‹éŸ³é¢‘ï¼‰', type='filepath')
    tts_text = gr.TextArea(label='TTSæ–‡æœ¬ï¼ˆåˆæˆæ–‡æœ¬ï¼‰',lines=5)
    speed_input, seed, use_25hz_flag = common_param_layout()
    
    return sample_audio, tts_text, speed_input, seed, use_25hz_flag

def cosyvoice_fast_clone_node(mode):
    '''
    CosyVoiceå¿«é€Ÿå…‹éš†èŠ‚ç‚¹å¸ƒå±€
    mode: model æ¨¡å‹æ¨¡å¼ï¼Œmodel æ¨¡å‹æ¨¡å¼
    '''
    if mode == 'model':
        file_hide = False
    else:
        file_hide = True

    tts_text = gr.TextArea(label='TTSæ–‡æœ¬ï¼ˆåˆæˆæ–‡æœ¬ï¼‰',lines=3)
    prompt_text = gr.TextArea(label='Promptæ–‡æœ¬ï¼ˆæ ·ä¾‹éŸ³é¢‘æ–‡æœ¬ï¼‰',lines=3, visible=file_hide)
    speaker_model_name = gr.Textbox(label='è¯­éŸ³æ¨¡å‹åç§°')
    speaker_model_dir = gr.Textbox(label='è¯­éŸ³æ¨¡å‹ç›®å½•', value=speaker_path)
    sample_audio = gr.Audio(label='é‡‡æ ·éŸ³é¢‘æ–‡ä»¶ï¼ˆæ ·ä¾‹éŸ³é¢‘ï¼‰', type='filepath', visible=file_hide)
    speed_input, seed, use_25hz_flag = common_param_layout()
    
    return sample_audio, speaker_model_name, speaker_model_dir, tts_text, prompt_text, speed_input, seed, use_25hz_flag

def app_launcher():
    '''
    ä¸»ç•Œé¢å¸ƒå±€
    '''
    
    with gr.Blocks(fill_height=True) as app:
        gr.Markdown('''
        # ğŸ‘‹ FunAudioLLM TTSå·¥å…·
        ''')

        with gr.Tab('è¯­éŸ³è¯†åˆ«'):
            gr.Markdown('''
            ### ä½¿ç”¨SenseVoiceè¯†åˆ«éŸ³é¢‘ï¼Œæå–æ–‡å­—ã€‚
            step1. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼›<br/>
            step2. è®¾ç½®å‚æ•°ï¼›<br/>
            step3. ç‚¹å‡»è¯†åˆ«æŒ‰é’®ï¼Œæå–æ–‡å­—ã€‚
            ''')
            audio_input, use_fast_model, punc_segment = sensevoice_layout()
            get_text_btn = gr.Button('è¯†åˆ«')
            text_ouput = gr.TextArea(label='è¯†åˆ«ç»“æœ', lines=9, show_label=True, show_copy_button=True)

        with gr.Tab('è¯­éŸ³ç”Ÿæˆ(é¢„è®­ç»ƒæ¨¡å‹)'):
            gr.Markdown('''
            ### ä½¿ç”¨CosyVoiceçš„é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚
            step1. è¾“å…¥TTSæ–‡æœ¬ï¼›<br/>
            step2. é€‰æ‹©é¢„è®­ç»ƒçš„è§’è‰²æ¨¡å‹ï¼›<br/>
            step3. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›<br/>
            step4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆè¯­éŸ³ã€‚
            ''')
            tts_text_for_predefined, predefined_model, speed_input, seed, use_25hz_flag = cosyvoice_pretrained_model_node()
            create_voice_by_predefined_btn = gr.Button('ç”Ÿæˆ')
            voice_predefined = gr.Audio(label='ç”Ÿæˆè¯­éŸ³')

        with gr.Tab('è‡ªç„¶è¯­è¨€æ§åˆ¶è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            ### ä½¿ç”¨CosyVoiceçš„é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚
            step1. è¾“å…¥TTSæ–‡æœ¬ã€‚ç›®å‰æ”¯æŒçš„æŒ‡ä»¤&lt;laughter&gt;&lt;/laughter&gt;&lt;strong&gt;&lt;/strong&gt;[laughter][breath]ï¼›<br/>
            step2. è¾“å…¥Instructæ–‡æœ¬ï¼Œç”¨äºæè¿°è¯­éŸ³çš„çŠ¶æ€ï¼Œå¦‚ï¼›A female speaker with normal pitch, slow speaking rate, and sad emotion.<br/>
            step3. é€‰æ‹©é¢„è®­ç»ƒçš„æ¨¡å‹ï¼›<br/>
            step4. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›<br/>
            step5. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆè¯­éŸ³ã€‚
            ''')
            tts_text_for_natural_lang, instruct_text, predefined_model2, speed_input2, seed2 = cosyvoice_natural_lang_control_node()
            create_voice_by_natural_lang_btn = gr.Button('ç”Ÿæˆ')
            voice_natural = gr.Audio(label='ç”Ÿæˆè¯­éŸ³')
    
        with gr.Tab('è·¨è¯­ç§è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            ### ä½¿ç”¨é‡‡æ ·éŸ³é¢‘å’ŒCosyVideoé¢„å®šä¹‰æ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚
            step1. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œç¡®å®šéŸ³è‰²ï¼›<br/>
            step2. è¾“å…¥TTSæ–‡æœ¬ï¼›<br/>
            step3. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›<br/>
            step4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆè¯­éŸ³ã€‚
            ''')
            sample_audio3, tts_text_for_dual_lang, speed_input3, seed3, use_25hz_flag3 = cosyvoice_dual_lang_clone_node()
            create_voice_by_dual_lang_btn = gr.Button('ç”Ÿæˆ')
            voice_dual_lang = gr.Audio(label='ç”Ÿæˆè¯­éŸ³')

        mode = 'model'
        with gr.Tab('è¯­éŸ³æ¨¡å‹è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            ### é€šè¿‡CosyVoiceï¼Œä½¿ç”¨è‡ªè®­ç»ƒçš„è¯­éŸ³æ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚
            step1. è¾“å…¥TTSæ–‡æœ¬ï¼›<br/>
            step2. è¾“å…¥æ¨¡å‹çš„åç§°å’Œç›®å½•ï¼›<br/>
            step3. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›<br/>
            step4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆè¯­éŸ³ã€‚
            ''')
            speaker_audio4, speaker_model_name, speaker_model_dir, tts_text4, prompt_text4, speed_input4, seed4, use_25hz_flag4 = cosyvoice_fast_clone_node(mode)
            create_voice_by_cloned_model_btn = gr.Button("ç”Ÿæˆ")
            cloned_voice = gr.Audio(label="ç”Ÿæˆè¯­éŸ³")

        mode = 'file'
        with gr.Tab('è¯­éŸ³å…‹éš†æ¨¡å‹'):
            gr.Markdown('''
            ### ä½¿ç”¨CosyVoiceç”Ÿæˆè¯­éŸ³å…‹éš†æ¨¡å‹ã€‚
            step1. è¾“å…¥TTSæ–‡æœ¬ï¼Œç”¨äºç”Ÿæˆæ¨¡å‹çš„æµ‹è¯•è¯­éŸ³ï¼›<br/>
            step2. è¾“å…¥Promptæ–‡æœ¬ï¼Œè¿™ä¸ªéœ€è¦å’Œstep3ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶å†…å®¹ä¸€è‡´ï¼›<br/>
            step3. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œæ˜¯ç”¨äºç”Ÿæˆæ¨¡å‹çš„æºéŸ³é¢‘ï¼›<br/>
            step4. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›<br/>
            step5. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆæ¨¡å‹å’Œæµ‹è¯•è¯­éŸ³ã€‚
            ''')
            sample_audio5, speaker_model_name5, speaker_model_dir5, tts_text5, prompt_text5, speed_input5, seed5, use_25hz_flag5 = cosyvoice_fast_clone_node(mode)
            create_voice_model_btn = gr.Button("ç”Ÿæˆ")
            voice_output6 = gr.Audio(label="ç”Ÿæˆè¯­éŸ³")
            voice_model6 = gr.File(label="ç”Ÿæˆè¯­éŸ³æ¨¡å‹")

        get_text_btn.click(
            fn=get_text_by_sensevoice,
            inputs=[audio_input, use_fast_model, punc_segment],
            outputs=text_ouput
        )

        create_voice_by_predefined_btn.click(
            fn=create_voice_by_pretrained,
            inputs=[tts_text_for_predefined, predefined_model, speed_input, seed, use_25hz_flag], 
            outputs=voice_predefined
        )

        create_voice_by_natural_lang_btn.click(
            fn=create_voice_by_natural_lang,
            inputs=[tts_text_for_natural_lang, instruct_text, predefined_model2, speed_input2, seed2],
            outputs=voice_natural
        )

        create_voice_by_dual_lang_btn.click(
            fn=create_voice_by_dual_lang,
            inputs=[sample_audio3, tts_text_for_dual_lang, speed_input3, seed3, use_25hz_flag3],
            outputs=voice_dual_lang
        )
        
        create_voice_by_cloned_model_btn.click(
            fn=create_voice_by_cloned_model,
            inputs=[speaker_model_name, speaker_model_dir, tts_text4, speed_input4, seed4, use_25hz_flag4],
            outputs=cloned_voice
        )

        create_voice_model_btn.click(
            fn=create_voice_model,
            inputs=[sample_audio5, speaker_model_name5, speaker_model_dir5, tts_text5, prompt_text5, speed_input5, seed5, use_25hz_flag5],
            outputs=[voice_output6, voice_model6]
        )

        gr.HTML("""
        <style>
            #seed-row > * {  /* Style all direct children of the row */
                display: flex;
                align-items: center;
                height: 60px; /* Or whatever height you want */
            }
            #seed-row > button { /* Target the button directly */
                witdh: 30px; /* Prevent button from shrinking */
                margin-right: -15px; /* Add some space between the button and the input */
            }
        </style>
        """)

    return app

def main():
    app = app_launcher()
    app.launch()

if __name__ == '__main__':
    main()