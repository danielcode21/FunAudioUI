'''
Author: Daniel
'''
import gradio as gr
import os
import random
from funaudiowarp import SenseVoiceNode
from funaudiowarp import CosyVoiceSFTNode, CosyVoiceNaturalNode, CosyVoiceDualLanglNode, CosyVoiceSpeakerVoiceNode, CosyVoiceSpeakerCreaterNode
from funaudio_utils.download_models import ModelDownloader

base_path = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(base_path, "models")
speaker_path = os.path.join(model_path, 'Speaker')
model_downloader = ModelDownloader(model_path)

sft_spk_list = ['ä¸­æ–‡å¥³', 'ä¸­æ–‡ç”·', 'æ—¥è¯­ç”·', 'ç²¤è¯­å¥³', 'è‹±æ–‡å¥³', 'è‹±æ–‡ç”·', 'éŸ©è¯­å¥³']
def get_text_by_sensevoice(audio_input, use_fast_model, punc_segment):
    '''
    è°ƒç”¨SenseVoiceçš„è¯­éŸ³è¯†åˆ«æ¥å£
    '''
    sensevoice_node = SenseVoiceNode(base_path, model_downloader)
    return sensevoice_node.generate(audio_input, use_fast_model, punc_segment)

def create_voice_by_pretrained(tts_text, predefined_model, speed_input, seed, use_25hz_flag):
    '''
    è°ƒç”¨CosyVoiceçš„é¢„å®šä¹‰æ¨¡å‹ç”Ÿæˆè¯­éŸ³
    '''
    cosyvoice_sft_node = CosyVoiceSFTNode(base_path, model_downloader)
    output = cosyvoice_sft_node.generate(tts_text, predefined_model, float(speed_input), int(seed), use_25hz_flag)
    return output

def create_voice_by_natural_lang(tts_text_for_natural_lang, instruct_text, predefined_model, speed_input, seed):
    '''
    è°ƒç”¨CosyVoiceçš„é¢„å®šä¹‰æ¨¡å‹å’ŒæŒ‡ä»¤æ–‡æœ¬ç”Ÿæˆè¯­éŸ³
    '''
    cosyvoice_natural_node = CosyVoiceNaturalNode(base_path, model_downloader)
    output = cosyvoice_natural_node.generate(tts_text_for_natural_lang, instruct_text, predefined_model, float(speed_input), int(seed))
    return output

def create_voice_by_dual_lang(sample_audio, tts_text_for_dual_lang, speed_input, seed, use_25hz_flag):
    '''
    ä½¿ç”¨è·¨è¯­è¨€æ¨¡å‹ç”Ÿæˆè¯­éŸ³
    '''
    cosyvoice_dual_lang_node = CosyVoiceDualLanglNode(base_path, model_downloader)
    output = cosyvoice_dual_lang_node.generate(sample_audio, tts_text_for_dual_lang, float(speed_input), int(seed), use_25hz_flag)
    return output

def create_voice_by_cloned_model(speaker_model_name, speaker_model_dir, tts_text, speed_input, seed, use_25hz_flag):
    '''
    ä½¿ç”¨å…‹éš†è¯­éŸ³æ¨¡å‹æŒ‰é’®
    '''
    cosyvoice_speaker_voice_node = CosyVoiceSpeakerVoiceNode(base_path, model_downloader)
    output = cosyvoice_speaker_voice_node.generate(speaker_model_name, speaker_model_dir, tts_text, float(speed_input), int(seed), use_25hz_flag)
    return output

def create_voice_model(sample_audio, speaker_model_name, speaker_model_dir, tts_text, prompt_text, speed_input, seed, use_25hz_flag):
    '''
    ç”Ÿæˆè¯­éŸ³å…‹éš†æ¨¡å‹
    '''
    cosyvoice_speaker_create_node = CosyVoiceSpeakerCreaterNode(base_path, model_downloader)
    output = cosyvoice_speaker_create_node.generate(sample_audio, tts_text, prompt_text, speaker_model_name, speaker_model_dir, float(speed_input), int(seed), use_25hz_flag)
    return output

def generate_seed():
    '''
    ç”Ÿæˆéšæœºç§å­
    '''
    seed = random.randint(1, 100000000)
    return seed

def common_param_layout():
    '''
    é€šç”¨çš„å‚æ•°å¸ƒå±€
    '''
    with gr.Column('CosyVoiceå…‹éš†æ¨¡å‹'):
        with gr.Row():
            with gr.Column():
                speed_input = gr.Slider(label="è¯­é€Ÿ", minimum=0.5, maximum=2.0, step=0.1, value=1.0, min_width=100)
            with gr.Group():
                with gr.Column():
                    seed = gr.Number(label='éšæœºç§å­', value=generate_seed(),  min_width=100)
                with gr.Column():
                    seed_btn = gr.Button("ğŸ²", min_width=20)
            
        with gr.Row():
            use_25hz_flag = gr.Checkbox(label='ä½¿ç”¨25Hzé‡‡æ ·ç‡', value=False)

    seed_btn.click(
        fn=generate_seed,
        inputs=[],
        outputs=[seed]
    )

    return speed_input, seed, seed_btn, use_25hz_flag
 
def sensevoice_layout():
    '''
    SenseVoiceèŠ‚ç‚¹å¸ƒå±€
    '''
    with gr.Column('SenseVoice'):
        with gr.Group():
            audio_input = gr.Audio(label='æºéŸ³é¢‘æ–‡ä»¶')
        with gr.Group():
            use_fast_model = gr.Checkbox(label='ä½¿ç”¨å¿«é€Ÿæ¨¡å‹', value=False)
            punc_segment = gr.Checkbox(label='æ·»åŠ æ ‡ç‚¹ç¬¦å·', value=True)
    
    return audio_input, use_fast_model, punc_segment
                                 
def cosyvoice_pretrained_model_node():
    '''
    CosyVoiceé¢„å®šä¹‰æ¨¡å‹çš„èŠ‚ç‚¹å¸ƒå±€
    '''
    with gr.Column('CosyVoiceé¢„å®šä¹‰æ¨¡å‹'):
        with gr.Group():
            tts_text = gr.TextArea(label='TTSæ–‡æœ¬',lines=5)
        with gr.Group():
            predefined_model = gr.Dropdown(choices=sft_spk_list, label='é¢„å®šä¹‰è§’è‰²æ¨¡å‹', value='ä¸­æ–‡å¥³')
            speed_input, seed, seed_btn, use_25hz_flag = common_param_layout()
   
    return tts_text, predefined_model, speed_input, seed, seed_btn, use_25hz_flag

def cosyvoice_natural_lang_control_node():
    '''
    CosyVoiceè‡ªç„¶è¯­è¨€æ§åˆ¶èŠ‚ç‚¹å¸ƒå±€
    '''
    with gr.Column('CosyVoiceè‡ªç„¶è¯­è¨€æ§åˆ¶'):
        with gr.Group():
            tts_text = gr.TextArea(label='TTSæ–‡æœ¬',lines=5)
        with gr.Group():
            instruct_text = gr.TextArea(label='Instructæ–‡æœ¬',lines=3)
        with gr.Group():
            predefined_model = gr.Dropdown(choices=sft_spk_list, label='é¢„å®šä¹‰è§’è‰²æ¨¡å‹', value='ä¸­æ–‡å¥³')
            speed_input, seed, seed_btn, _ = common_param_layout()
    
    return tts_text, instruct_text, predefined_model, speed_input, seed, seed_btn

def cosyvoice_dual_lang_clone_node():
    '''
    CosyVoiceè·¨è¯­è¨€å…‹éš†èŠ‚ç‚¹å¸ƒå±€
    '''
    with gr.Column('CosyVoiceè·¨è¯­è¨€å…‹éš†'):
        with gr.Group():
            sample_audio = gr.Audio(label='é‡‡æ ·éŸ³é¢‘æ–‡ä»¶', type='filepath')
        
        with gr.Group():
            tts_text = gr.TextArea(label='TTSæ–‡æœ¬',lines=5)
        
        with gr.Group():
            speed_input, seed, seed_btn, use_25hz_flag = common_param_layout()
    
    return sample_audio, tts_text, speed_input, seed, seed_btn, use_25hz_flag

def cosyvoice_fast_clone_node(mode):
    '''
    CosyVoiceå¿«é€Ÿå…‹éš†èŠ‚ç‚¹å¸ƒå±€
    mode: model æ¨¡å‹æ¨¡å¼ï¼Œmodel æ¨¡å‹æ¨¡å¼
    '''
    if mode == 'model':
        file_hide = False
    else:
        file_hide = True

    with gr.Column('CosyVoiceå¿«é€Ÿå…‹éš†'):
        with gr.Group():
            tts_text = gr.TextArea(label='TTSæ–‡æœ¬',lines=3)

        with gr.Group():
            prompt_text = gr.TextArea(label='Promptæ–‡æœ¬',lines=3, visible=file_hide)

        with gr.Group():
            speaker_model_name = gr.Textbox(label='è¯­éŸ³æ¨¡å‹åç§°')
            speaker_model_dir = gr.Textbox(label='è¯­éŸ³æ¨¡å‹ç›®å½•', value=speaker_path)
        
        with gr.Group():
            sample_audio = gr.Audio(label='é‡‡æ ·éŸ³é¢‘æ–‡ä»¶', type='filepath', visible=file_hide)

        with gr.Group():
            speed_input, seed, seed_btn, use_25hz_flag = common_param_layout()
    
        return sample_audio, speaker_model_name, speaker_model_dir, tts_text, prompt_text, speed_input, seed, seed_btn, use_25hz_flag

def app_launcher():
    '''
    ä¸»ç•Œé¢å¸ƒå±€
    '''
    
    with gr.Blocks() as app:
        gr.Markdown('''
        # ğŸ‘‹ FunAudioLLM TTSå·¥å…·
        ''')

        with gr.Tab('è¯­éŸ³è¯†åˆ«'):
            gr.Markdown('''
            ä½¿ç”¨SenseVoiceè¯†åˆ«éŸ³é¢‘ï¼Œæå–æ–‡å­—ã€‚
            step1. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼›
            step2. è®¾ç½®å‚æ•°ï¼›
            step3. ç‚¹å‡»è¯†åˆ«æŒ‰é’®ï¼Œæå–æ–‡å­—ã€‚
            ''')
            with gr.Row():
                with gr.Column():
                    audio_input, use_fast_model, punc_segment = sensevoice_layout()
                    get_text_btn = gr.Button('è¯†åˆ«')
                with gr.Column():
                    text_ouput = gr.TextArea(label='è¯†åˆ«ç»“æœ', lines=9, show_label=True, show_copy_button=True)

        with gr.Tab('è¯­éŸ³ç”Ÿæˆ(é¢„è®­ç»ƒæ¨¡å‹)'):
            gr.Markdown('''
            ä½¿ç”¨CosyVoiceçš„é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚
            step1. è¾“å…¥TTSæ–‡æœ¬ï¼›
            step2. é€‰æ‹©é¢„è®­ç»ƒçš„è§’è‰²æ¨¡å‹ï¼›
            step3. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›
            step4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆè¯­éŸ³ã€‚
            ''')
            with gr.Row():
                with gr.Column():
                    tts_text_for_predefined, predefined_model, speed_input, seed, seed_btn, use_25hz_flag = cosyvoice_pretrained_model_node()
                    create_voice_by_predefined_btn = gr.Button('ç”Ÿæˆ')
                with gr.Column():
                    voice_predefined = gr.Audio(label='ç”Ÿæˆè¯­éŸ³')

        with gr.Tab('è‡ªç„¶è¯­è¨€æ§åˆ¶è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            ä½¿ç”¨CosyVoiceçš„é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚
            step1. è¾“å…¥TTSæ–‡æœ¬ï¼›
            step2. è¾“å…¥Instructæ–‡æœ¬ï¼Œç”¨äºæè¿°è§’è‰²çš„è¯´è¯ç‰¹ç‚¹ï¼›
            step3. é€‰æ‹©é¢„è®­ç»ƒçš„è§’è‰²æ¨¡å‹ï¼›
            step4. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›
            step5. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆè¯­éŸ³ã€‚
            ''')
            with gr.Row():
                with gr.Column():
                    tts_text_for_natural_lang, instruct_text, predefined_model2, speed_input2, seed2, seed_btn2 = cosyvoice_natural_lang_control_node()
                    create_voice_by_natural_lang_btn = gr.Button('ç”Ÿæˆ')
                with gr.Column():
                    voice_natural = gr.Audio(label='ç”Ÿæˆè¯­éŸ³')
        
        with gr.Tab('è·¨è¯­ç§è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            ä½¿ç”¨é‡‡æ ·éŸ³é¢‘å’ŒCosyVideoé¢„å®šä¹‰æ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚
            step1. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œç¡®å®šéŸ³è‰²ï¼›
            step2. è¾“å…¥TTSæ–‡æœ¬ï¼›
            step3. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›
            step4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆè¯­éŸ³ã€‚
            ''')
            with gr.Row():
                with gr.Column():
                    sample_audio3, tts_text_for_dual_lang, speed_input3, seed3, seed_btn3, use_25hz_flag3 = cosyvoice_dual_lang_clone_node()
                    create_voice_by_dual_lang_btn = gr.Button('ç”Ÿæˆ')
                with gr.Column():
                    voice_dual_lang = gr.Audio(label='ç”Ÿæˆè¯­éŸ³')

        mode = 'model'
        with gr.Tab('è¯­éŸ³æ¨¡å‹è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            é€šè¿‡CosyVoiceï¼Œä½¿ç”¨è‡ªè®­ç»ƒçš„è¯­éŸ³æ¨¡å‹ç”Ÿæˆè¯­éŸ³ã€‚
            step1. è¾“å…¥TTSæ–‡æœ¬ï¼›
            step2. è¾“å…¥æ¨¡å‹çš„åç§°å’Œç›®å½•ï¼›
            step3. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›
            step4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆè¯­éŸ³ã€‚
            ''')
            with gr.Row():
                with gr.Column():
                    speaker_audio4, speaker_model_name, speaker_model_dir, tts_text4, prompt_text4, speed_input4, seed4, seed_btn4, use_25hz_flag4 = cosyvoice_fast_clone_node(mode)
                    create_voice_by_cloned_model_btn = gr.Button("ç”Ÿæˆ")

                with gr.Column():
                    cloned_voice = gr.Audio(label="ç”Ÿæˆè¯­éŸ³")

        mode = 'file'
        with gr.Tab('è¯­éŸ³å…‹éš†æ¨¡å‹'):
            gr.Markdown('''
            ä½¿ç”¨CosyVoiceç”Ÿæˆè¯­éŸ³å…‹éš†æ¨¡å‹ã€‚
            step1. è¾“å…¥TTSæ–‡æœ¬ï¼Œç”¨äºç”Ÿæˆæ¨¡å‹çš„æµ‹è¯•è¯­éŸ³ï¼›
            step2. è¾“å…¥Promptæ–‡æœ¬ï¼Œè¿™ä¸ªéœ€è¦å’Œstep3ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶å†…å®¹ä¸€è‡´ï¼›
            step3. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œæ˜¯ç”¨äºç”Ÿæˆæ¨¡å‹çš„æºéŸ³é¢‘ï¼›
            step4. è®¾ç½®è¯­é€Ÿç­‰å‚æ•°ï¼›
            step5. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç”Ÿæˆæ¨¡å‹å’Œæµ‹è¯•è¯­éŸ³ã€‚
            ''')
            with gr.Row():
                with gr.Column():
                    sample_audio5, speaker_model_name5, speaker_model_dir5, tts_text5, prompt_text5, speed_input5, seed5, seed_btn5, use_25hz_flag5 = cosyvoice_fast_clone_node(mode)
                    create_voice_model_btn = gr.Button("ç”Ÿæˆ")

                with gr.Column():
                    voice_output6 = gr.Audio(label="ç”Ÿæˆè¯­éŸ³")
                    voice_model6 = gr.File(label="ç”Ÿæˆè¯­éŸ³æ¨¡å‹")

        get_text_btn.click(
            fn=get_text_by_sensevoice,
            inputs=[audio_input, use_fast_model, punc_segment],
            outputs=text_ouput
        )

        create_voice_by_predefined_btn.click(
            fn=create_voice_by_pretrained,
            inputs=[tts_text_for_predefined, predefined_model, speed_input, seed, use_25hz_flag], 
            outputs=voice_predefined
        )

        create_voice_by_natural_lang_btn.click(
            fn=create_voice_by_natural_lang,
            inputs=[tts_text_for_natural_lang, instruct_text, predefined_model2, speed_input2, seed2],
            outputs=voice_natural
        )

        create_voice_by_dual_lang_btn.click(
            fn=create_voice_by_dual_lang,
            inputs=[sample_audio3, tts_text_for_dual_lang, speed_input3, seed3, use_25hz_flag3],
            outputs=voice_dual_lang
        )
        
        create_voice_by_cloned_model_btn.click(
            fn=create_voice_by_cloned_model,
            inputs=[speaker_model_name, speaker_model_dir, tts_text4, speed_input4, seed4, use_25hz_flag4],
            outputs=cloned_voice
        )

        create_voice_model_btn.click(
            fn=create_voice_model,
            inputs=[sample_audio5, speaker_model_name5, speaker_model_dir5, tts_text5, prompt_text5, speed_input5, seed5, use_25hz_flag5],
            outputs=[voice_output6, voice_model6]
        )

    return app

def main():
    app = app_launcher()
    app.launch()

if __name__ == '__main__':
    main()