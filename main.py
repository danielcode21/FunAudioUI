'''
Author: Daniel
'''
import gradio as gr
import os
from funaudiowarp import SenseVoiceNode
from funaudiowarp import CosyVoiceSFTNode
from funaudio_utils.download_models import ModelDownloader

base_path = os.path.dirname(os.path.abspath(__file__))
model_downloader = ModelDownloader(os.path.join(base_path, "models"))

sft_spk_list = ['ä¸­æ–‡å¥³', 'ä¸­æ–‡ç”·', 'æ—¥è¯­ç”·', 'ç²¤è¯­å¥³', 'è‹±æ–‡å¥³', 'è‹±æ–‡ç”·', 'éŸ©è¯­å¥³']
def get_text_by_sensevoice(audio_input, use_fast_model, punc_segment):
    '''
    è°ƒç”¨SenseVoiceçš„è¯­éŸ³è¯†åˆ«æ¥å£
    '''
    #print(f'audio_input={audio_input}, use_fast_model={use_fast_model}, punc_segment={punc_segment}')
    sensevoice_node = SenseVoiceNode(base_path, model_downloader)
    return sensevoice_node.generate(audio_input, use_fast_model, punc_segment)
def create_voice_by_predefined(tts_text, predefined_model, speed_input, seed, use_25hz_flag):
    '''
    è°ƒç”¨CosyVoiceçš„é¢„å®šä¹‰æ¨¡å‹ç”Ÿæˆè¯­éŸ³
    '''
    #print(f'tts_text={tts_text}, predefined_model={predefined_model}, speed_input={speed_input}, seed={seed}, use_25hz_flag={use_25hz_flag}')
    cosyvoice_sft_node = CosyVoiceSFTNode(base_path, model_downloader)
    output = cosyvoice_sft_node.generate(tts_text, predefined_model, float(speed_input), int(seed), use_25hz_flag)
    return output
def create_voice_by_natural_lang(tts_text_for_natural_lang, instruct_text, predefined_model, speed_input, seed):
    '''
    è°ƒç”¨CosyVoiceçš„é¢„å®šä¹‰æ¨¡å‹å’ŒæŒ‡ä»¤æ–‡æœ¬ç”Ÿæˆè¯­éŸ³
    '''
    print(f'tts_text_for_natural_lang={tts_text_for_natural_lang}, instruct_text={instruct_text}, predefined_model={predefined_model}, speed_input={speed_input}, seed={seed}')

def create_voice_by_dual_lang(sample_audio, tts_text_for_dual_lang, speed_input, seed, use_25hz_flag):
    '''
    ä½¿ç”¨è·¨è¯­è¨€æ¨¡å‹ç”Ÿæˆè¯­éŸ³
    '''
    print(f'sample_audio={sample_audio}, tts_text_for_dual_lang={tts_text_for_dual_lang}, speed_input={speed_input}, seed={seed}, use_25hz_flag={use_25hz_flag}')
def create_voice_by_cloned_model(speaker_model_name, speaker_model_dir, tts_text, prompt_text, speed_input, seed, use_25hz_flag):
    '''
    ä½¿ç”¨å…‹éš†è¯­éŸ³æ¨¡å‹æŒ‰é’®
    '''
    print(f'speaker_model_name={speaker_model_name}, speaker_model_dir={speaker_model_dir}, tts_text={tts_text}, prompt_text={prompt_text}, speed_input={speed_input}, seed={seed}, use_25hz_flag={use_25hz_flag}')

def create_voice_model(sample_audio, tts_text, prompt_text, speed_input, seed, use_25hz_flag):
    '''
    ç”Ÿæˆè¯­éŸ³å…‹éš†æ¨¡å‹
    '''
    print(f'sample_audio={sample_audio}, tts_text={tts_text}, prompt_text={prompt_text}, speed_input={speed_input}, seed={seed}, use_25hz_flag={use_25hz_flag}')

def sensevoice_layout():
    '''
    SenseVoiceèŠ‚ç‚¹å¸ƒå±€
    '''
    with gr.Column('SenseVoice'):
        with gr.Group():
            audio_input = gr.Audio(label='æºéŸ³é¢‘æ–‡ä»¶')
        with gr.Group():
            use_fast_model = gr.Checkbox(label='ä½¿ç”¨å¿«é€Ÿæ¨¡å‹', value=False)
            punc_segment = gr.Checkbox(label='æ·»åŠ æ ‡ç‚¹ç¬¦å·', value=True)
    
    return audio_input, use_fast_model, punc_segment
                                 
def cosyvoice_predefined_model_node():
    '''
    CosyVoiceé¢„å®šä¹‰æ¨¡å‹çš„èŠ‚ç‚¹å¸ƒå±€
    '''
    with gr.Column('CosyVoiceé¢„å®šä¹‰æ¨¡å‹'):
        with gr.Group():
            tts_text = gr.TextArea(label='TTSæ–‡æœ¬',lines=3)
        with gr.Group():
            predefined_model = gr.Dropdown(choices=sft_spk_list, label='é¢„å®šä¹‰è§’è‰²æ¨¡å‹', value='ä¸­æ–‡å¥³')
            speed_input = gr.Textbox(label='è¯­é€Ÿ', value='1.0')
            seed = gr.Textbox(label='éšæœºç§å­', value='1738')
            use_25hz_flag = gr.Checkbox(label='ä½¿ç”¨25hz', value=False)
   
    return tts_text, predefined_model, speed_input, seed, use_25hz_flag

def cosyvoice_natural_lang_control_node():
    '''
    CosyVoiceè‡ªç„¶è¯­è¨€æ§åˆ¶èŠ‚ç‚¹å¸ƒå±€
    '''
    with gr.Column('CosyVoiceè‡ªç„¶è¯­è¨€æ§åˆ¶'):
        with gr.Group():
            tts_text = gr.TextArea(label='TTSæ–‡æœ¬',lines=3)
        with gr.Group():
            instruct_text = gr.TextArea(label='Instructæ–‡æœ¬',lines=3)
        with gr.Group():
            predefined_model = gr.Dropdown(choices=sft_spk_list, label='é¢„å®šä¹‰è§’è‰²æ¨¡å‹', value='ä¸­æ–‡å¥³')
            speed_input = gr.Textbox(label='è¯­é€Ÿ', value='1.0')
            seed = gr.Textbox(label='éšæœºç§å­', value='1738')
    
    return tts_text, instruct_text, predefined_model, speed_input, seed

def cosyvoice_dual_lang_clone_node():
    '''
    CosyVoiceè·¨è¯­è¨€å…‹éš†èŠ‚ç‚¹å¸ƒå±€
    '''
    with gr.Column('CosyVoiceè·¨è¯­è¨€å…‹éš†'):
        with gr.Group():
            sample_audio = gr.Audio(label='é‡‡æ ·éŸ³é¢‘æ–‡ä»¶')
        
        with gr.Group():
            tts_text = gr.TextArea(label='TTSæ–‡æœ¬',lines=3)
        
        with gr.Group():
            speed_input = gr.Textbox(label='è¯­é€Ÿ', value='1.0')
            seed = gr.Textbox(label='éšæœºç§å­', value='1738')
            use_25hz_flag = gr.Checkbox(label='ä½¿ç”¨25hz', value=False)
    
    return sample_audio, tts_text, speed_input, seed, use_25hz_flag

def cosyvoice_fast_clone_node(mode):
    '''
    CosyVoiceå¿«é€Ÿå…‹éš†èŠ‚ç‚¹å¸ƒå±€
    mode: model æ¨¡å‹æ¨¡å¼ï¼Œmodel æ¨¡å‹æ¨¡å¼
    '''
    if mode == 'model':
        mode_hide = True
        file_hide = False
    else:
        mode_hide = False
        file_hide = True

    with gr.Column('CosyVoiceå¿«é€Ÿå…‹éš†'):
        with gr.Group():
            tts_text = gr.TextArea(label='TTSæ–‡æœ¬',lines=3)

        with gr.Group():
            prompt_text = gr.TextArea(label='Promptæ–‡æœ¬',lines=3)

        with gr.Group():
                speaker_model_name = gr.Textbox(label='è¯­éŸ³æ¨¡å‹åç§°', visible=mode_hide)
                speaker_model_dir = gr.Textbox(label='è¯­éŸ³æ¨¡å‹ç›®å½•', visible=mode_hide)
        
        with gr.Group():
                sample_audio = gr.Audio(label='é‡‡æ ·éŸ³é¢‘æ–‡ä»¶', visible=file_hide)

        
        with gr.Group():
            speed_input = gr.Textbox(label='è¯­é€Ÿ', value='1.0')
            seed = gr.Textbox(label='éšæœºç§å­', value='1738')
            use_25hz_flag = gr.Checkbox(label='ä½¿ç”¨25hz', value=False)
    
        return sample_audio, speaker_model_name, speaker_model_dir, tts_text, prompt_text, speed_input, seed, use_25hz_flag

def app_launcher():
    '''
    ä¸»ç•Œé¢å¸ƒå±€
    '''
    
    with gr.Blocks() as app:
        gr.Markdown('''
        # ğŸ‘‹ Hello World!
        ''')

        with gr.Tab('è¯­éŸ³è¯†åˆ«'):
            gr.Markdown('''
            ä½¿ç”¨SenseVoiceè¯†åˆ«éŸ³é¢‘ï¼Œç”Ÿæˆæ–‡å­—
            ''')
            with gr.Row():
                with gr.Column():
                    audio_input, use_fast_model, punc_segment = sensevoice_layout()
                    get_text_btn = gr.Button('è¯†åˆ«')
                with gr.Column():
                    text_ouput = gr.TextArea(label='è¯†åˆ«ç»“æœ', lines=7, show_label=True, show_copy_button=True)

        with gr.Tab('è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            ä½¿ç”¨CosyVoiceçš„é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¯­éŸ³
            ''')
            with gr.Row():
                with gr.Column():
                    tts_text_for_predefined, predefined_model, speed_input, seed, use_25hz_flag = cosyvoice_predefined_model_node()
                    create_voice_by_predefined_btn = gr.Button('ç”Ÿæˆ')
                with gr.Column():
                    voice_predefined = gr.Audio(label='ç”Ÿæˆè¯­éŸ³')

        with gr.Tab('è‡ªç„¶è¯­è¨€è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            ä½¿ç”¨CosyVoiceçš„é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè¯­éŸ³
            ''')
            with gr.Row():
                with gr.Column():
                    tts_text_for_natural_lang, instruct_text, predefined_model2, speed_input2, seed2 = cosyvoice_natural_lang_control_node()
                    create_voice_by_natural_lang_btn = gr.Button('ç”Ÿæˆ')
                with gr.Column():
                    voice_natural = gr.Audio(label='ç”Ÿæˆè¯­éŸ³')
        
        with gr.Tab('è·¨è¯­ç§è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            ä½¿ç”¨é‡‡æ ·éŸ³é¢‘å’ŒCosyVideoé¢„å®šä¹‰æ¨¡å‹ç”Ÿæˆè¯­éŸ³
            ''')
            with gr.Row():
                with gr.Column():
                    sample_audio3, tts_text_for_dual_lang, speed_input3, seed3, use_25hz_flag3 = cosyvoice_dual_lang_clone_node()
                    create_voice_by_dual_lang_btn = gr.Button('ç”Ÿæˆ')
                with gr.Column():
                    voice_dual_lang = gr.Audio(label='ç”Ÿæˆè¯­éŸ³')

        mode = 'model'
        with gr.Tab('è¯­éŸ³æ¨¡å‹è¯­éŸ³ç”Ÿæˆ'):
            gr.Markdown('''
            é€šè¿‡CosyVoiceï¼Œä½¿ç”¨è‡ªå®šä¹‰çš„è¯­éŸ³æ¨¡å‹ç”Ÿæˆè¯­éŸ³
            ''')
            with gr.Row():
                with gr.Column():
                    sample_audio4, speaker_model_name, speaker_model_dir, tts_text4, prompt_text4, speed_input4, seed4, use_25hz_flag4 = cosyvoice_fast_clone_node(mode)
                    create_voice_by_cloned_model_btn = gr.Button("ç”Ÿæˆ")

                with gr.Column():
                    cloned_voice = gr.Audio(label="ç”Ÿæˆè¯­éŸ³")

        mode = 'file'
        with gr.Tab('è¯­éŸ³å…‹éš†æ¨¡å‹'):
            gr.Markdown('''
            ä½¿ç”¨CosyVoiceç”Ÿæˆè¯­éŸ³å…‹éš†æ¨¡å‹
            ''')
            with gr.Row():
                with gr.Column():
                    sample_audio5, speaker_model_name5, speaker_model_dir5, tts_text5, prompt_text5, speed_input5, seed5, use_25hz_flag5 = cosyvoice_fast_clone_node(mode)
                    create_voice_model_btn = gr.Button("ç”Ÿæˆ")

                with gr.Column():
                    voice_output6 = gr.Audio(label="ç”Ÿæˆè¯­éŸ³")
                    voice_model6 = gr.File(label="ç”Ÿæˆè¯­éŸ³æ¨¡å‹")

        get_text_btn.click(
            fn=get_text_by_sensevoice,
            inputs=[audio_input, use_fast_model, punc_segment],
            outputs=text_ouput
        )

        create_voice_by_predefined_btn.click(
            fn=create_voice_by_predefined,
            inputs=[tts_text_for_predefined, predefined_model, speed_input, seed, use_25hz_flag], 
            outputs=voice_predefined
        )

        create_voice_by_natural_lang_btn.click(
            fn=create_voice_by_natural_lang,
            inputs=[tts_text_for_natural_lang, instruct_text, predefined_model2, speed_input2, seed2],
            outputs=voice_natural
        )

        create_voice_by_dual_lang_btn.click(
            fn=create_voice_by_natural_lang,
            inputs=[sample_audio3, tts_text_for_dual_lang, speed_input3, seed3, use_25hz_flag3],
            outputs=voice_dual_lang
        )
        
        create_voice_by_cloned_model_btn.click(
            fn=create_voice_by_cloned_model,
            inputs=[speaker_model_name, speaker_model_dir, tts_text4, prompt_text4, speed_input4, seed4, use_25hz_flag4],
            outputs=cloned_voice
        )

        create_voice_model_btn.click(
            fn=create_voice_model,
            inputs=[sample_audio5, tts_text5, prompt_text5, speed_input5, seed5, use_25hz_flag5],
            outputs=[voice_output6, voice_model6]
        )

    return app
def main():
    app = app_launcher()
    app.launch()

if __name__ == '__main__':
    main()